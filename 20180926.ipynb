{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20180926.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/modeverv/JupyterNotebook/blob/master/20180926.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "DPF3SzrwRxzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "de1f61b3-a0f5-4d84-e680-7c0e0dbbcfb5"
      },
      "cell_type": "code",
      "source": [
        "!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!pip install cupy-cuda80 chainer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
            "0 upgraded, 3 newly installed, 0 to remove and 0 not upgraded.\n",
            "Need to get 28.9 MB of archives.\n",
            "After this operation, 71.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu artful/multiverse amd64 libcusparse8.0 amd64 8.0.61-1 [22.6 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu artful/multiverse amd64 libnvrtc8.0 amd64 8.0.61-1 [6,225 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu artful/multiverse amd64 libnvtoolsext1 amd64 8.0.61-1 [32.2 kB]\n",
            "Fetched 28.9 MB in 7s (3,673 kB/s)\n",
            "Selecting previously unselected package libcusparse8.0:amd64.\n",
            "(Reading database ... 18408 files and directories currently installed.)\n",
            "Preparing to unpack .../libcusparse8.0_8.0.61-1_amd64.deb ...\n",
            "Unpacking libcusparse8.0:amd64 (8.0.61-1) ...\n",
            "Selecting previously unselected package libnvrtc8.0:amd64.\n",
            "Preparing to unpack .../libnvrtc8.0_8.0.61-1_amd64.deb ...\n",
            "Unpacking libnvrtc8.0:amd64 (8.0.61-1) ...\n",
            "Selecting previously unselected package libnvtoolsext1:amd64.\n",
            "Preparing to unpack .../libnvtoolsext1_8.0.61-1_amd64.deb ...\n",
            "Unpacking libnvtoolsext1:amd64 (8.0.61-1) ...\n",
            "Setting up libnvtoolsext1:amd64 (8.0.61-1) ...\n",
            "Setting up libcusparse8.0:amd64 (8.0.61-1) ...\n",
            "Setting up libnvrtc8.0:amd64 (8.0.61-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Collecting cupy-cuda80\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/e2/a335e07f9b40b7e16a1aa04924b18c538ce763237ac7b5137caffc1c9a3a/cupy_cuda80-4.5.0-cp36-cp36m-manylinux1_x86_64.whl (200.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 200.7MB 168kB/s \n",
            "\u001b[?25hCollecting chainer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/ae/5b08a1717187ef98127b5d68ec700009b9c8a918b40319813e3e89f2254f/chainer-4.5.0.tar.gz (402kB)\n",
            "\u001b[K    100% |████████████████████████████████| 409kB 12.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (1.14.6)\n",
            "Collecting fastrlock>=0.3 (from cupy-cuda80)\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/93/a7efbd39eac46c137500b37570c31dedc2d31a8ff4949fcb90bda5bc5f16/fastrlock-0.4-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (1.11.0)\n",
            "Collecting filelock (from chainer)\n",
            "  Downloading https://files.pythonhosted.org/packages/85/1c/389ca4da8b631a06dec64c94c9c6f22bbd9be236f0030ee4863e7d6e42a7/filelock-3.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0.0->chainer) (39.1.0)\n",
            "Building wheels for collected packages: chainer\n",
            "  Running setup.py bdist_wheel for chainer ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/4f/a5/e6/b0cbcc4cc1daeaab566096480d5b9aed9106de601daf1006f8\n",
            "Successfully built chainer\n",
            "Installing collected packages: fastrlock, cupy-cuda80, filelock, chainer\n",
            "Successfully installed chainer-4.5.0 cupy-cuda80-4.5.0 fastrlock-0.4 filelock-3.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w8buq7feSOcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e54f4605-302b-4c8a-b4fa-6058be89252f"
      },
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "x = cp.arange(6).reshape(2, 3).astype('f')\n",
        "x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 2.],\n",
              "       [3., 4., 5.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "mKoTPrSfSwzp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdd3b3b6-e174-4242-acf0-9ef0e5eb6330"
      },
      "cell_type": "code",
      "source": [
        "1 + 1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "EOzuFV8M7_Dz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bc70d701-4cb9-4cbf-9949-de8748a8ed4a"
      },
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "import numpy as np\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "\n",
        "text = text.lower()\n",
        "text = text.replace('.', ' .')\n",
        "words = text.split(' ')\n",
        "print(words)\n",
        "\n",
        "word_to_id = {}\n",
        "id_to_word = {}\n",
        "for word in words:\n",
        "    if word not in word_to_id:\n",
        "        new_id = len(word_to_id)\n",
        "        word_to_id[word] = new_id\n",
        "        id_to_word[new_id] = word\n",
        "\n",
        "print(word_to_id)\n",
        "print(id_to_word)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "corpus = [word_to_id[w] for w in words]\n",
        "corpus = np.array(corpus)\n",
        "print(corpus)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']\n",
            "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
            "[0 1 2 3 4 1 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7keTbsMwI-Iq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = text.replace('.', ' .')\n",
        "    words = text.split(' ')\n",
        "    word_to_id = {}\n",
        "    id_to_word = {}\n",
        "    for word in words:\n",
        "        if word not in word_to_id:\n",
        "            new_id = len(word_to_id)\n",
        "            word_to_id[word] = new_id\n",
        "            id_to_word[new_id] = word\n",
        "    corpus = np.array([word_to_id[w] for w in words])\n",
        "    return corpus, word_to_id, id_to_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "med8RUZ1JBpS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95b42ab9-cd06-4eb6-d815-40fc327af30d"
      },
      "cell_type": "code",
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "print(word_to_id)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_A8OruKezQm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFXRdR5xzAqN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cos_similarity(x, y,eps=1e-8):\n",
        "    nx=x / (np.sqrt(np.sum(x ** 2)) + eps)\n",
        "    ny=y / (np.sqrt(np.sum(y ** 2)) + eps)\n",
        "    return np.dot(nx, ny)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ILL3FR5tzO0r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
        "    corpus_size = len(corpus)\n",
        "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
        "    for idx, word_id in enumerate(corpus):\n",
        "        for i in range(1, window_size + 1):\n",
        "            left_idx = idx - i\n",
        "            right_idx = idx + i\n",
        "\n",
        "            if left_idx >= 0:\n",
        "                left_word_id = corpus[left_idx]\n",
        "                co_matrix[word_id, left_word_id] += 1\n",
        "\n",
        "            if right_idx < corpus_size:\n",
        "                right_word_id = corpus[right_idx]\n",
        "                co_matrix[word_id, right_word_id] += 1\n",
        "    return co_matrix\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXgxgeL8zGEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "902c44e0-26da-452e-c80e-ab3838bb0d34"
      },
      "cell_type": "code",
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "c0 = C[word_to_id['you']] #「you」の単語ベクトル\n",
        "c1 = C[word_to_id['i']] #「i」の単語ベクトル\n",
        "print(cos_similarity(c0, c1))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7071067691154799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WjzNqAUnzGvW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
        "    if query not in word_to_id:\n",
        "        print(\"%s is not found\" % query)\n",
        "        return\n",
        "    \n",
        "    print(\"\\n[query] \" + query)\n",
        "    query_id = word_to_id[query]\n",
        "    query_vec = word_matrix[query_id]\n",
        "\n",
        "    vocab_size = len(id_to_word)\n",
        "    similarity = np.zeros(vocab_size)\n",
        "    for i in range(vocab_size):\n",
        "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
        "    \n",
        "    count = 0\n",
        "    for i in (-1 * similarity).argsort():\n",
        "        if id_to_word[i] == query:\n",
        "            continue\n",
        "        print(\"%s: %s\" % (id_to_word[i], similarity[i]))\n",
        "        count += 1\n",
        "        if count >= top:\n",
        "            return\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hw3hvpYf5_dV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d0969caa-0ac9-4d43-e451-9bc81aeeea5f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "most_similar('you', word_to_id, id_to_word, C, top=5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[query] you\n",
            "goodbye: 0.7071067691154799\n",
            "i: 0.7071067691154799\n",
            "hello: 0.7071067691154799\n",
            "say: 0.0\n",
            "and: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxxPewdb6AID",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ppmi(C, verbose=False, eps=1e-8):\n",
        "    M=np.zeros_like(C, dtype=np.float32)\n",
        "    N=np.sum(C)\n",
        "    S=np.sum(C, axis=0)\n",
        "    total=C.shape[0] * C.shape[1]\n",
        "    cnt=0\n",
        "\n",
        "    for i in range(C.shape[0]):\n",
        "        for j in range(C.shape[1]):\n",
        "            pmi = np.log2(C[i, j] * N / (S[j] * S[i]) + eps)\n",
        "            M[i, j] = max(0, pmi)\n",
        "            if verbose:\n",
        "                cnt += 1\n",
        "                if cnt % (total // 100) == 0:\n",
        "                    print(\"%.1f%% done\" % (100 * cnt / total))\n",
        "    \n",
        "    return M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CDshszslNKRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "bc58a64a-ab46-433e-d78f-e29a41fc2332"
      },
      "cell_type": "code",
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(word_to_id)\n",
        "C = create_co_matrix(corpus, vocab_size)\n",
        "W = ppmi(C)\n",
        "np.set_printoptions(precision=3) # 有効桁3桁で表示\n",
        "print('covariance matrix')\n",
        "print(C)\n",
        "print('-'*50)\n",
        "print('PPMI')\n",
        "print(W)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "covariance matrix\n",
            "[[0 1 0 0 0 0 0]\n",
            " [1 0 1 0 1 1 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0]\n",
            " [0 1 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0]]\n",
            "--------------------------------------------------\n",
            "PPMI\n",
            "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
            " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
            " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
            " [0.    0.807 0.    0.    0.    0.    2.807]\n",
            " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GBebTd1ee2Et",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Driveをマウントする\n",
        "# Google Driveにあるdeep-learning-from-scratch-2のライブラリを読み込む例\n"
      ]
    },
    {
      "metadata": {
        "id": "pposJPK3b6za",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d4b613c5-78c7-422d-bfe4-792bd60ab043"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "libr =  '/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2'\n",
        "sys.path.append(libr)\n",
        "print(sys.path)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from common.util import preprocess, create_co_matrix, ppmi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CKYMXxz6cJ00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "87bf4113-c416-4643-9e2e-a8c6709ef1db"
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ch01  ch03  ch05  ch07\tcommon\t LICENSE.md\n",
            "ch02  ch04  ch06  ch08\tdataset  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mTNRbTkqOJth",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "72701a23-b025-4ae2-ec8e-6d1c0ea4dc1e"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "libr =  '/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2'\n",
        "sys.path.append(libr)\n",
        "print(sys.path)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from common.util import preprocess, create_co_matrix, ppmi\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "vocab_size = len(id_to_word)\n",
        "C = create_co_matrix(corpus, vocab_size, window_size=1)\n",
        "W = ppmi(C)\n",
        "\n",
        "# SVD\n",
        "U, S, V = np.linalg.svd(W)\n",
        "for word, word_id in word_to_id.items():\n",
        "    plt.annotate(word, (U[word_id, 0],U[word_id,1]))\n",
        "\n",
        "plt.scatter(U[:,0], U[:,1],alpha=0.5)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2', '..', '/content/drive/My Drive/Colab Notebooks/deep-learning-from-scratch-2']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFKCAYAAADWhMzpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f047a408080>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7pCqakkFNMNL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbcc6815-e634-48ea-89e8-c4259160822a"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'drive': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H2FvAU_1dghk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2244
        },
        "outputId": "506ef34d-6127-424e-b105-f36dbfe7499b"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from common.util import most_similar, create_co_matrix, ppmi\n",
        "from dataset import ptb\n",
        "\n",
        "window_size = 2\n",
        "wordvec_size = 100\n",
        "try:\n",
        "    from sklearn.utils.extmath import randomized_svd\n",
        "except ImportError:\n",
        "    print(\"can't import\")\n",
        "    exit()\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "vocab_size = len(word_to_id)\n",
        "print('counting  co-occurrence ...')\n",
        "C = create_co_matrix(corpus, vocab_size, window_size)\n",
        "print('calculating PPMI ...')\n",
        "W = ppmi(C, verbose=True)\n",
        "\n",
        "print('calculating SVD ...')\n",
        "try:\n",
        "    # truncated SVD (fast!)\n",
        "\n",
        "    from sklearn.utils.extmath import randomized_svd\n",
        "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5,\n",
        "                             random_state=None)\n",
        "except ImportError:\n",
        "    # SVD (slow)\n",
        "    print(\"slow\")\n",
        "    U, S, V = np.linalg.svd(W)\n",
        "\n",
        "word_vecs = U[:, :wordvec_size]\n",
        "\n",
        "querys = ['you', 'year', 'car', 'toyota']\n",
        "for query in querys:\n",
        "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counting  co-occurrence ...\n",
            "calculating PPMI ...\n",
            "1.0% done\n",
            "2.0% done\n",
            "3.0% done\n",
            "4.0% done\n",
            "5.0% done\n",
            "6.0% done\n",
            "7.0% done\n",
            "8.0% done\n",
            "9.0% done\n",
            "10.0% done\n",
            "11.0% done\n",
            "12.0% done\n",
            "13.0% done\n",
            "14.0% done\n",
            "15.0% done\n",
            "16.0% done\n",
            "17.0% done\n",
            "18.0% done\n",
            "19.0% done\n",
            "20.0% done\n",
            "21.0% done\n",
            "22.0% done\n",
            "23.0% done\n",
            "24.0% done\n",
            "25.0% done\n",
            "26.0% done\n",
            "27.0% done\n",
            "28.0% done\n",
            "29.0% done\n",
            "30.0% done\n",
            "31.0% done\n",
            "32.0% done\n",
            "33.0% done\n",
            "34.0% done\n",
            "35.0% done\n",
            "36.0% done\n",
            "37.0% done\n",
            "38.0% done\n",
            "39.0% done\n",
            "40.0% done\n",
            "41.0% done\n",
            "42.0% done\n",
            "43.0% done\n",
            "44.0% done\n",
            "45.0% done\n",
            "46.0% done\n",
            "47.0% done\n",
            "48.0% done\n",
            "49.0% done\n",
            "50.0% done\n",
            "51.0% done\n",
            "52.0% done\n",
            "53.0% done\n",
            "54.0% done\n",
            "55.0% done\n",
            "56.0% done\n",
            "57.0% done\n",
            "58.0% done\n",
            "59.0% done\n",
            "60.0% done\n",
            "61.0% done\n",
            "62.0% done\n",
            "63.0% done\n",
            "64.0% done\n",
            "65.0% done\n",
            "66.0% done\n",
            "67.0% done\n",
            "68.0% done\n",
            "69.0% done\n",
            "70.0% done\n",
            "71.0% done\n",
            "72.0% done\n",
            "73.0% done\n",
            "74.0% done\n",
            "75.0% done\n",
            "76.0% done\n",
            "77.0% done\n",
            "78.0% done\n",
            "79.0% done\n",
            "80.0% done\n",
            "81.0% done\n",
            "82.0% done\n",
            "83.0% done\n",
            "84.0% done\n",
            "85.0% done\n",
            "86.0% done\n",
            "87.0% done\n",
            "88.0% done\n",
            "89.0% done\n",
            "90.0% done\n",
            "91.0% done\n",
            "92.0% done\n",
            "93.0% done\n",
            "94.0% done\n",
            "95.0% done\n",
            "96.0% done\n",
            "97.0% done\n",
            "98.0% done\n",
            "99.0% done\n",
            "100.0% done\n",
            "calculating SVD ...\n",
            "\n",
            "[query] you\n",
            " i: 0.6929749846458435\n",
            " we: 0.6390077471733093\n",
            " do: 0.6375547051429749\n",
            " anybody: 0.5656633377075195\n",
            " someone: 0.5568373799324036\n",
            "\n",
            "[query] year\n",
            " quarter: 0.6750348806381226\n",
            " earlier: 0.6397271752357483\n",
            " month: 0.6369876861572266\n",
            " next: 0.6179594397544861\n",
            " last: 0.5919192433357239\n",
            "\n",
            "[query] car\n",
            " auto: 0.5229128003120422\n",
            " truck: 0.5222605466842651\n",
            " luxury: 0.5097161531448364\n",
            " cars: 0.4977967441082001\n",
            " vehicle: 0.48645561933517456\n",
            "\n",
            "[query] toyota\n",
            " motor: 0.7533544301986694\n",
            " motors: 0.6817812323570251\n",
            " honda: 0.6577357053756714\n",
            " mazda: 0.643952488899231\n",
            " lexus: 0.6345124840736389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OBwGerqUbKRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1720
        },
        "outputId": "237d670c-a7c1-4e6c-a9ff-6793a18b070c"
      },
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo\n",
        "!cat /proc/meminfo"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm pti fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms xsaveopt arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 l1tf\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm pti fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms xsaveopt arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 l1tf\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "MemTotal:       13335236 kB\n",
            "MemFree:         7125584 kB\n",
            "MemAvailable:   11454308 kB\n",
            "Buffers:           51992 kB\n",
            "Cached:          4203484 kB\n",
            "SwapCached:            0 kB\n",
            "Active:          1447972 kB\n",
            "Inactive:        4427860 kB\n",
            "Active(anon):    1201892 kB\n",
            "Inactive(anon):   164952 kB\n",
            "Active(file):     246080 kB\n",
            "Inactive(file):  4262908 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               704 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       1618456 kB\n",
            "Mapped:           344312 kB\n",
            "Shmem:            257020 kB\n",
            "Slab:             159964 kB\n",
            "SReclaimable:     122788 kB\n",
            "SUnreclaim:        37176 kB\n",
            "KernelStack:        4260 kB\n",
            "PageTables:         7988 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6667616 kB\n",
            "Committed_AS:    3744804 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:           0 kB\n",
            "VmallocChunk:          0 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "DirectMap4k:      178164 kB\n",
            "DirectMap2M:     8210432 kB\n",
            "DirectMap1G:     7340032 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9-HmEO8MeiSh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}